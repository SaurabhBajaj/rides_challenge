{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import geohash\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import pytz\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>start_geohash</th>\n",
       "      <th>end_geohash</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>weekday</th>\n",
       "      <th>geo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>dr5rsj</td>\n",
       "      <td>dr5rsp</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>dr5rsj:dr5rsp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>dr5rus</td>\n",
       "      <td>dr5ruy</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>dr5rus:dr5ruy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>dr5rvj</td>\n",
       "      <td>dr5rvn</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>dr5rvj:dr5rvn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>dr5ru2</td>\n",
       "      <td>dr72jh</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>dr5ru2:dr72jh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>dr5rug</td>\n",
       "      <td>dr5ruq</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>dr5rug:dr5ruq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>dr5ru2</td>\n",
       "      <td>dr5rst</td>\n",
       "      <td>20</td>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>dr5ru2:dr5rst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>dr5ruu</td>\n",
       "      <td>dr5ru0</td>\n",
       "      <td>22</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>dr5ruu:dr5ru0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>dr5ru1</td>\n",
       "      <td>dr5ru5</td>\n",
       "      <td>11</td>\n",
       "      <td>58</td>\n",
       "      <td>5</td>\n",
       "      <td>dr5ru1:dr5ru5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>dr5rvj</td>\n",
       "      <td>dr5ru6</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>dr5rvj:dr5ru6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>dr5rus</td>\n",
       "      <td>dr5ruv</td>\n",
       "      <td>13</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>dr5rus:dr5ruv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id start_geohash end_geohash  hour  minute  weekday            geo\n",
       "0       0        dr5rsj      dr5rsp     3      13        6  dr5rsj:dr5rsp\n",
       "1       1        dr5rus      dr5ruy    13       2        1  dr5rus:dr5ruy\n",
       "2       2        dr5rvj      dr5rvn    13       2        1  dr5rvj:dr5rvn\n",
       "3       3        dr5ru2      dr72jh     4       8        3  dr5ru2:dr72jh\n",
       "4       4        dr5rug      dr5ruq    23       9        2  dr5rug:dr5ruq\n",
       "5       5        dr5ru2      dr5rst    20      41        3  dr5ru2:dr5rst\n",
       "6       6        dr5ruu      dr5ru0    22      37        5  dr5ruu:dr5ru0\n",
       "7       7        dr5ru1      dr5ru5    11      58        5  dr5ru1:dr5ru5\n",
       "8       8        dr5rvj      dr5ru6    23      22        2  dr5rvj:dr5ru6\n",
       "9       9        dr5rus      dr5ruv    13      56        3  dr5rus:dr5ruv"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### CONSTRUCT FINAL DATAFRAME FROM INPUT\n",
    "### CONSTRUCT FINAL DATAFRAME FROM INPUT\n",
    "### CONSTRUCT FINAL DATAFRAME FROM INPUT\n",
    "### CONSTRUCT FINAL DATAFRAME FROM INPUT\n",
    "### CONSTRUCT FINAL DATAFRAME FROM INPUT\n",
    "\n",
    "def get_time_vector(hour, week):\n",
    "    arr = numpy.zeros(168, dtype=float)\n",
    "    arr[hour * week] = 1.0\n",
    "\n",
    "def transform_dataset(df):\n",
    "    def get_geohash_from_concat_latlon(latlon):\n",
    "        lat, lon = latlon.split(\":\")\n",
    "        lat = float(lat)\n",
    "        lon = float(lon)        \n",
    "        precision = 6  \n",
    "        if (lat < -1000.0 or lat > 1000.0 or lon < -1000.0 or lon > 1000.0):\n",
    "            return 0\n",
    "        return geohash.encode(lat, lon, precision)\n",
    "\n",
    "    tz = pytz.timezone('America/New_York')\n",
    "    def get_local_time(timestamp):\n",
    "        d = datetime.utcfromtimestamp(timestamp).replace(tzinfo=pytz.utc)\n",
    "        dt = d.astimezone(tz)\n",
    "        return dt\n",
    "\n",
    "    def get_start_of_the_day(start_timestamp):\n",
    "        return start_timestamp.replace(hour=0, minute=0, second=0)\n",
    "\n",
    "    \n",
    "    def get_hour_block(hour):\n",
    "        if hour >= 0 and hour <= 3:\n",
    "            return 0\n",
    "        elif hour > 7 and hour <= 7\n",
    "#     d[\"geo\"] = d[\"start_geohash\"] + \":\" + d[\"end_geohash\"]\n",
    "    start_geo_1 = df[\"start_lat\"].astype(str) + \":\" + df[\"start_lng\"].astype(str)\n",
    "    start_geo = start_geo_1.apply(get_geohash_from_concat_latlon)\n",
    "    start_geo.name = 'start_geohash'\n",
    "    df = pd.concat([df, start_geo], axis = 1)    \n",
    "    del start_geo_1\n",
    "\n",
    "    end_geo_1 = df[\"end_lat\"].astype(str) + \":\" + df[\"end_lng\"].astype(str)\n",
    "    end_geo = end_geo_1.apply(get_geohash_from_concat_latlon)\n",
    "    end_geo.name = 'end_geohash'\n",
    "    df = pd.concat([df, end_geo], axis = 1)    \n",
    "    del end_geo_1\n",
    "    \n",
    "    start_time = df[\"start_timestamp\"].apply(get_local_time)\n",
    "    start_time.name = 'start_timestamp_obj'\n",
    "    df = pd.concat([df, start_time], axis = 1)    \n",
    "    # start_time[:10]\n",
    "\n",
    "    start = df[\"start_timestamp_obj\"].apply(get_start_of_the_day)\n",
    "    start.name = 'start_of_day'\n",
    "    df = pd.concat([df, start], axis = 1)\n",
    "\n",
    "    hour = df[\"start_timestamp_obj\"].dt.hour\n",
    "    hour.name = 'hour'\n",
    "    df = pd.concat([df, hour], axis = 1)\n",
    "\n",
    "    minute = df[\"start_timestamp_obj\"].dt.minute\n",
    "    minute.name = 'minute'\n",
    "    df = pd.concat([df, minute], axis = 1)\n",
    "\n",
    "    weekday = df[\"start_timestamp_obj\"].dt.weekday\n",
    "    weekday.name = 'weekday'\n",
    "    df = pd.concat([df, weekday], axis = 1)\n",
    "\n",
    "    df[\"geo\"] = df[\"start_geohash\"] + \":\" + df[\"end_geohash\"]\n",
    "    \n",
    "    timeseries = pd.Series(df[\"hour\"], df[\"weekday\"])\n",
    "    del start_time\n",
    "    del end_geo\n",
    "    del hour\n",
    "    del minute\n",
    "    del weekday\n",
    "    outdf = df.copy()\n",
    "    outdf.drop('start_lng', axis=1, inplace=True)\n",
    "    outdf.drop('start_lat', axis=1, inplace=True)\n",
    "    outdf.drop('end_lng', axis=1, inplace=True)\n",
    "    outdf.drop('end_lat', axis=1, inplace=True)\n",
    "    outdf.drop('start_timestamp', axis=1, inplace=True)\n",
    "    outdf.drop('start_timestamp_obj', axis=1, inplace=True)\n",
    "    outdf.drop('start_of_day', axis=1, inplace=True)\n",
    "    return outdf\n",
    "#     df = pd.concat([df, pd.DataFrame(start_time, index=df.index)], axis = 1)\n",
    "dfff = pd.read_csv(\"test.csv\")\n",
    "d = dfff[:100].copy()\n",
    "d = transform_dataset(d)\n",
    "d[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GET training dataset\n",
    "inputdf = pd.read_csv(\"train.csv\")\n",
    "df = inputdf\n",
    "df = transform_dataset(df)\n",
    "finalized_data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = transform_dataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read the model from file \n",
    "inputdf = pd.read_csv(\"train_mod.csv\")\n",
    "df = inputdf\n",
    "finalized_data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GET testing dataset\n",
    "inputdf = pd.read_csv(\"train.csv\")\n",
    "df = inputdf\n",
    "df = transform_dataset(df)\n",
    "finalized_data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25811430\n"
     ]
    }
   ],
   "source": [
    "start_geohashes = df[\"start_geohash\"]\n",
    "end_geohashes = df[\"end_geohash\"]\n",
    "print len(start_geohashes) + len(end_geohashes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GENERATE dictionary of geohashes and reverse_dictionary\n",
    "\n",
    "from collections import defaultdict\n",
    "dictionary = {}\n",
    "reverse_dictionary = {}\n",
    "start_list = list(df['start_geohash'])\n",
    "end_list = list(df['end_geohash'])\n",
    "geoset = set(start_list + end_list)\n",
    "\n",
    "for i, item in enumerate(geoset):\n",
    "    dictionary[i] = item\n",
    "    reverse_dictionary[item] = i\n",
    "\n",
    "tup = defaultdict(list)\n",
    "def geo_mapping(combo):\n",
    "    start, end, duration = combo.split(\":\")\n",
    "    tup[start].append((int(duration), end))\n",
    "    \n",
    "# df[\"geo\"] = df[\"start_geohash\"] + \":\" + df[\"end_geohash\"] + \":\" + df[\"duration\"].astype(str)\n",
    "_ = df[\"geo\"].apply(geo_mapping)\n",
    "\n",
    "\n",
    "sorted_tup = {}\n",
    "for k, v in tup.iteritems():\n",
    "    sorted_tup[k] = sorted(tup[k])[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### generate a data pipeline for the model input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Convert geohashes into a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### may be add avg speed at the geohash-time as a feature?\n",
    "### what about feature vector that is a combo of geohash/timewindow/\n",
    "### write the input into separate files"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
